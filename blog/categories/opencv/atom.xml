<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: OpenCV | 唐巧的技术博客]]></title>
  <link href="http://blog.devtang.com/blog/categories/opencv/atom.xml" rel="self"/>
  <link href="http://blog.devtang.com/"/>
  <updated>2015-04-29T17:21:54+08:00</updated>
  <id>http://blog.devtang.com/</id>
  <author>
    <name><![CDATA[唐巧]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[在MacOS和iOS系统中使用OpenCV]]></title>
    <link href="http://blog.devtang.com/blog/2012/10/27/use-opencv-in-ios/"/>
    <updated>2012-10-27T20:43:00+08:00</updated>
    <id>http://blog.devtang.com/blog/2012/10/27/use-opencv-in-ios</id>
    <content type="html"><![CDATA[<h2>前言</h2>

<p><img src="/images/opencv.png"></p>

<p><a href="http://opencv.org/about.html">OpenCV</a> 是一个开源的跨平台计算机视觉库，实现了图像处理和计算机视觉方面的很多通用算法。</p>

<p>最近试着在MacOS和iOS上使用OpenCV，发现网上关于在MacOS和iOS上搭建OpenCV的资料很少。好不容易搜到些资料，却发现由于OpenCV和XCode的版本更新，变得不再有用了。有些问题费了我很多时间，在此总结分享给大家，希望后来人少走些弯路。</p>

<p>可以预见到，随着XCode和OpenCV的版本更新，本文可能不再有效了。</p>

<p>所以特此注明，文本介绍的搭建方法仅针对于 XCode4.5.1 和 OpenCV 2.4.2版本。</p>

<p>（2013-6-22）更新: 我在XCode4.6.2 和 OpenCV 2.4.5版本的时候重新进行了一次环境搭建，以下内容做了相应调整，应该也是有效的。</p>

<!-- more -->


<h2>MacOS系统中使用OpenCV</h2>

<h3>在Mac OS Lion中安装OpenCV</h3>

<p>相信大部分Mac用户都安装了brew或port，如果你没有装，那么首先安装一下brew吧。使用如下命令安装brew:</p>

<p><code>bash
ruby -e "$(curl -fsSkL raw.github.com/mxcl/homebrew/go)"
</code></p>

<p>在安装好brew后，只需要一条命令就可以安装OpenCV了：
<code>bash
brew install opencv
</code></p>

<p>通常情况下这样做就应该会安装成功，但我在公司和家里面的电脑尝试的时候，brew都会报一些错误，我遇到的都是一些小问题，按照brew的提示信息，解决掉相应的问题即可。</p>

<p>安装成功后，你应该可以在“/usr/local/include"目录下找到名为opencv和opencv2的目录，这里面是OpenCV相关的头文件。你也可以在“/usr/local/lib"目录下找到许多以libopencv_开头的.dylib文件，这些是OpenCV的链接库文件。</p>

<h3>在Mac OS Mountain Lion中安装OpenCV</h3>

<p>按照<a href="http://tilomitra.com/opencv-on-mac-osx/">该教程</a>，先用brew安装cmake.</p>

<p>去<a href="http://opencv.org/">OpenCV官网</a>下载Linux/Mac版的源码，将源码解压后，在控制台中切换到源码目录，执行如下操作：</p>

<p>``` bash</p>

<h1>make a separate directory for building</h1>

<p>mkdir build
cd build
cmake -G &ldquo;Unix Makefiles&rdquo; ..</p>

<h1>Now, we can make OpenCV. Type the following in:</h1>

<p>make -j8
sudo make install
```</p>

<p>上面的命令在执行时要注意，整个源码目录的路径不能带空格。否则编译会报错找不到一些文件。</p>

<p>安装成功后，你应该可以在“/usr/local/include"目录下找到名为opencv和opencv2的目录，这里面是OpenCV相关的头文件。你也可以在“/usr/local/lib"目录下找到许多以libopencv_开头的.dylib文件，这些是OpenCV的链接库文件。</p>

<h3>在MacOS系统中使用OpenCV</h3>

<p>接着我们可以试着在Xcode工程中使用OpenCV。</p>

<p>新建一个Cocoa Application的工程。工程建好后，选中工程的Target，在Build Settings一样，找到“Header Search Paths"这一个选项，将它的值改为“/usr/local/include"。</p>

<p>同样还需要设置的还有"Lib Search Paths"这一项，将它的值改为"/usr/local/lib/**&ldquo;, 如下所示：</p>

<p><img src="/images/use-opencv-in-mac-1.jpg"></p>

<p>接着切换到Build Phases这个tab，在“Link Binary With Libraries"中，选项+号，然后将弹出的文件选择对话框目录切换到“/usr/local/lib"目录下，选择你需要使用的OpenCV链接库（通常情况下，你至少会需要core、highgui和imgproc库)，如下图所示（截图中的OpenCV版本号可能和你的有差别，但应该不影响）：</p>

<p><img src="/images/use-opencv-in-mac-2.png"></p>

<p>这里有一个技巧，因为 /usr 目录在对话框中默认不是可见的，可以按快捷键 command + shift + G，在弹出的“前往文件夹"对话框中输入 /usr/local/lib ，即可跳转到目标文件夹。如下图所示：</p>

<p><img src="/images/use-opencv-in-mac-3.png"></p>

<p>下一步是我自己试出来的，对于Lion操作系统，你需要在Build Settings中，将“C++ Language Dialect”设置成C++11，将“C++ Standard Library”设置成libstdc++ ，如下图所示。个人感觉是由于XCode默认设置的GNU++11、libc++与OpenCV库有一些兼容性问题，我在更改该设置前老是出现编译错误。后续版本在Montain Lion系统中解决了这个问题，不用进行这一步了。</p>

<p><img src="/images/use-opencv-in-mac-4.png"></p>

<p>把上面的设置都做好后，就可以在需要的使用OpenCV库的地方，加上opencv的头文件引用即可：</p>

<p>``` objc</p>

<h1>import &ldquo;opencv2/opencv.hpp&rdquo;</h1>

<p>```</p>

<p>注意，如果你的源文件扩展名是.m的，你还需要改成.mm，这样编译器才知道你将会在该文件混合使用C++语言和Objective-C语言。</p>

<p>OpenCV处理图象需要的格式是cv::Mat类，而MacOS的图象格式默认是NSImage，所以你需要知道如何在cv::Mat与NSImage之前相互转换。如下是一个NSImage的Addition，你肯定会需要它的。该代码来自stackoverflow上的<a href="http://stackoverflow.com/questions/8563356/nsimage-to-cvmat-and-vice-versa">这个贴子</a>。</p>

<p>NSImage+OpenCV.h 文件：
``` objc
//
//  NSImage+OpenCV.h
//
//  Created by TangQiao on 12-10-26.
//</p>

<h1>import &lt;Foundation/Foundation.h></h1>

<h1>import &ldquo;opencv2/opencv.hpp&rdquo;</h1>

<p>@interface NSImage (OpenCV)</p>

<p>+(NSImage*)imageWithCVMat:(const cv::Mat&amp;)cvMat;
&ndash;(id)initWithCVMat:(const cv::Mat&amp;)cvMat;</p>

<p>@property(nonatomic, readonly) cv::Mat CVMat;
@property(nonatomic, readonly) cv::Mat CVGrayscaleMat;</p>

<p>@end</p>

<p>```</p>

<p>NSImage+OpenCV.mm文件：
``` objc
//
//  NSImage+OpenCV.mm
//
//  Created by TangQiao on 12-10-26.
//</p>

<h1>import &ldquo;NSImage+OpenCV.h&rdquo;</h1>

<p>static void ProviderReleaseDataNOP(void <em>info, const void </em>data, size_t size)
{</p>

<pre><code>return;
</code></pre>

<p>}</p>

<p>@implementation NSImage (OpenCV)</p>

<p>&ndash;(CGImageRef)CGImage
{</p>

<pre><code>CGContextRef bitmapCtx = CGBitmapContextCreate(NULL/*data - pass NULL to let CG allocate the memory*/,
                                               [self size].width,
                                               [self size].height,
                                               8 /*bitsPerComponent*/,
                                               0 /*bytesPerRow - CG will calculate it for you if it's allocating the data.  This might get padded out a bit for better alignment*/,
                                               [[NSColorSpace genericRGBColorSpace] CGColorSpace],
                                               kCGBitmapByteOrder32Host|kCGImageAlphaPremultipliedFirst);

[NSGraphicsContext saveGraphicsState];
[NSGraphicsContext setCurrentContext:[NSGraphicsContext graphicsContextWithGraphicsPort:bitmapCtx flipped:NO]];
[self drawInRect:NSMakeRect(0,0, [self size].width, [self size].height) fromRect:NSZeroRect operation:NSCompositeCopy fraction:1.0];
[NSGraphicsContext restoreGraphicsState];

CGImageRef cgImage = CGBitmapContextCreateImage(bitmapCtx);
CGContextRelease(bitmapCtx);

return cgImage;
</code></pre>

<p>}</p>

<p>&ndash;(cv::Mat)CVMat
{</p>

<pre><code>CGImageRef imageRef = [self CGImage];
CGColorSpaceRef colorSpace = CGImageGetColorSpace(imageRef);
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;
cv::Mat cvMat(rows, cols, CV_8UC4); // 8 bits per component, 4 channels

CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNoneSkipLast |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), imageRef);
CGContextRelease(contextRef);
CGImageRelease(imageRef);
return cvMat;
</code></pre>

<p>}</p>

<p>&ndash;(cv::Mat)CVGrayscaleMat
{</p>

<pre><code>CGImageRef imageRef = [self CGImage];
CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceGray();
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;
cv::Mat cvMat = cv::Mat(rows, cols, CV_8UC1); // 8 bits per component, 1 channel
CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNone |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), imageRef);
CGContextRelease(contextRef);
CGColorSpaceRelease(colorSpace);
CGImageRelease(imageRef);
return cvMat;
</code></pre>

<p>}</p>

<ul>
<li><p>(NSImage *)imageWithCVMat:(const cv::Mat&amp;)cvMat
{
  return [[[NSImage alloc] initWithCVMat:cvMat] autorelease];
}</p></li>
<li><p>(id)initWithCVMat:(const cv::Mat&amp;)cvMat
{
  NSData *data = [NSData dataWithBytes:cvMat.data length:cvMat.elemSize() * cvMat.total()];</p>

<p>  CGColorSpaceRef colorSpace;</p>

<p>  if (cvMat.elemSize() == 1)
  {
      colorSpace = CGColorSpaceCreateDeviceGray();
  }
  else
  {
      colorSpace = CGColorSpaceCreateDeviceRGB();
  }</p>

<p>  CGDataProviderRef provider = CGDataProviderCreateWithCFData((CFDataRef)data);</p>

<p>  CGImageRef imageRef = CGImageCreate(cvMat.cols,                                     // Width
                                      cvMat.rows,                                     // Height
                                      8,                                              // Bits per component
                                      8 * cvMat.elemSize(),                           // Bits per pixel
                                      cvMat.step[0],                                  // Bytes per row
                                      colorSpace,                                     // Colorspace
                                      kCGImageAlphaNone | kCGBitmapByteOrderDefault,  // Bitmap info flags
                                      provider,                                       // CGDataProviderRef
                                      NULL,                                           // Decode
                                      false,                                          // Should interpolate
                                      kCGRenderingIntentDefault);                     // Intent</p>

<p>  NSBitmapImageRep <em>bitmapRep = [[NSBitmapImageRep alloc] initWithCGImage:imageRef];
  NSImage </em>image = [[NSImage alloc] init];
  [image addRepresentation:bitmapRep];</p>

<p>  CGImageRelease(imageRef);
  CGDataProviderRelease(provider);
  CGColorSpaceRelease(colorSpace);</p>

<p>  return image;
}</p></li>
</ul>


<p>@end</p>

<p>```</p>

<p>完成以上步骤后，恭喜你，你可以在源代码中自由地调用OpenCV的函数了。</p>

<h2>在iOS系统中使用OpenCV</h2>

<h4>下载或编译opencv2.framework</h4>

<p>接下来介绍如何在iOS程序中使用OpenCV。在iOS上使用最新的OpenCV库比较简单，进入<a href="http://opencv.org/">opencv的官网</a>，下载build好的名为opencv2.framework即可（<a href="http://sourceforge.net/projects/opencvlibrary/files/opencv-ios/2.4.3/opencv2.framework.zip/download?utm_expid=6384-3">下载地址</a>）。</p>

<p>如果你比较喜欢折腾，也可以自行下载opencv的源码，在本地编译opencv2.framework。<a href="http://docs.opencv.org/trunk/doc/tutorials/introduction/ios_install/ios_install.html#ios-installation">这里</a>有官方网站的教程，步骤非常简单，不过我照着它的教程尝试了一下失败了。感觉还是XCode编译器与OpenCV代码的兼容性问题，所以就没有继续研究了。</p>

<h4>在iOS程序中使用OpenCV</h4>

<p>新建一个iOS工程，将opencv2.framework直接拖动到工程中。然后，你需要在Build Settings中，将“C++ Standard Library”设置成libstdc++。</p>

<p>因为opencv中的MIN宏和UIKit的MIN宏有冲突。所以需要在.pch文件中，先定义opencv的头文件，否则会有编译错误。将工程的.pch文件内容修改成如下所示：</p>

<p>``` objc</p>

<h1>import &lt;Availability.h></h1>

<h1>ifdef __cplusplus</h1>

<pre><code>#import &lt;opencv2/opencv.hpp&gt;
</code></pre>

<h1>endif</h1>

<h1>ifdef <strong>OBJC</strong></h1>

<pre><code>#import &lt;UIKit/UIKit.h&gt;
#import &lt;Foundation/Foundation.h&gt;
</code></pre>

<h1>endif</h1>

<p>```</p>

<p>把上面的设置都做好后，就可以在需要的使用OpenCV库的地方，加上opencv的头文件引用即可：</p>

<p>``` objc</p>

<h1>import &ldquo;opencv2/opencv.hpp&rdquo;</h1>

<p>```</p>

<p>还是那句话，如果你的源文件扩展名是.m的，你还需要改成.mm，这样编译器才知道你将会在该文件中混合使用C++语言和Objective-C语言。</p>

<p>同样，iOS程序内部通常用UIImage表示图片，而OpenCV处理图象需要的格式是cv::Mat，你会需要下面这个Addition来在cv::Mat和UIImage格式之间相互转换。该代码来自<a href="https://github.com/aptogo/OpenCVForiPhone">aptogo的开源代码</a>，他的版权信息在源码头文件中。</p>

<p>UIImage+OpenCV.h 文件：
``` objc
//
//  UIImage+OpenCV.h
//  OpenCVClient
//
//  Created by Robin Summerhill on 02/09/2011.
//  Copyright 2011 Aptogo Limited. All rights reserved.
//
//  Permission is given to use this source code file without charge in any
//  project, commercial or otherwise, entirely at your risk, with the condition
//  that any redistribution (in part or whole) of source code must retain
//  this copyright and permission notice. Attribution in compiled projects is
//  appreciated but not required.
//</p>

<h1>import &lt;UIKit/UIKit.h></h1>

<p>@interface UIImage (UIImage_OpenCV)</p>

<p>+(UIImage *)imageWithCVMat:(const cv::Mat&amp;)cvMat;
&ndash;(id)initWithCVMat:(const cv::Mat&amp;)cvMat;</p>

<p>@property(nonatomic, readonly) cv::Mat CVMat;
@property(nonatomic, readonly) cv::Mat CVGrayscaleMat;</p>

<p>@end</p>

<p>```</p>

<p>UIImage+OpenCV.mm 文件：
``` objc
//
//  UIImage+OpenCV.mm
//  OpenCVClient
//
//  Created by Robin Summerhill on 02/09/2011.
//  Copyright 2011 Aptogo Limited. All rights reserved.
//
//  Permission is given to use this source code file without charge in any
//  project, commercial or otherwise, entirely at your risk, with the condition
//  that any redistribution (in part or whole) of source code must retain
//  this copyright and permission notice. Attribution in compiled projects is
//  appreciated but not required.
//</p>

<h1>import &ldquo;UIImage+OpenCV.h&rdquo;</h1>

<p>static void ProviderReleaseDataNOP(void <em>info, const void </em>data, size_t size)
{</p>

<pre><code>// Do not release memory
return;
</code></pre>

<p>}</p>

<p>@implementation UIImage (UIImage_OpenCV)</p>

<p>&ndash;(cv::Mat)CVMat
{</p>

<pre><code>CGColorSpaceRef colorSpace = CGImageGetColorSpace(self.CGImage);
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;

cv::Mat cvMat(rows, cols, CV_8UC4); // 8 bits per component, 4 channels

CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNoneSkipLast |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), self.CGImage);
CGContextRelease(contextRef);

return cvMat;
</code></pre>

<p>}</p>

<p>&ndash;(cv::Mat)CVGrayscaleMat
{</p>

<pre><code>CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceGray();
CGFloat cols = self.size.width;
CGFloat rows = self.size.height;

cv::Mat cvMat = cv::Mat(rows, cols, CV_8UC1); // 8 bits per component, 1 channel

CGContextRef contextRef = CGBitmapContextCreate(cvMat.data,                 // Pointer to backing data
                                                cols,                      // Width of bitmap
                                                rows,                     // Height of bitmap
                                                8,                          // Bits per component
                                                cvMat.step[0],              // Bytes per row
                                                colorSpace,                 // Colorspace
                                                kCGImageAlphaNone |
                                                kCGBitmapByteOrderDefault); // Bitmap info flags

CGContextDrawImage(contextRef, CGRectMake(0, 0, cols, rows), self.CGImage);
CGContextRelease(contextRef);
CGColorSpaceRelease(colorSpace);

return cvMat;
</code></pre>

<p>}</p>

<ul>
<li><p>(UIImage *)imageWithCVMat:(const cv::Mat&amp;)cvMat
{
  return [[[UIImage alloc] initWithCVMat:cvMat] autorelease];
}</p></li>
<li><p>(id)initWithCVMat:(const cv::Mat&amp;)cvMat
{
  NSData *data = [NSData dataWithBytes:cvMat.data length:cvMat.elemSize() * cvMat.total()];</p>

<p>  CGColorSpaceRef colorSpace;</p>

<p>  if (cvMat.elemSize() == 1)
  {
      colorSpace = CGColorSpaceCreateDeviceGray();
  }
  else
  {
      colorSpace = CGColorSpaceCreateDeviceRGB();
  }</p>

<p>  CGDataProviderRef provider = CGDataProviderCreateWithCFData((CFDataRef)data);</p>

<p>  CGImageRef imageRef = CGImageCreate(cvMat.cols,                                     // Width
                                      cvMat.rows,                                     // Height
                                      8,                                              // Bits per component
                                      8 * cvMat.elemSize(),                           // Bits per pixel
                                      cvMat.step[0],                                  // Bytes per row
                                      colorSpace,                                     // Colorspace
                                      kCGImageAlphaNone | kCGBitmapByteOrderDefault,  // Bitmap info flags
                                      provider,                                       // CGDataProviderRef
                                      NULL,                                           // Decode
                                      false,                                          // Should interpolate
                                      kCGRenderingIntentDefault);                     // Intent</p>

<p>  self = [self initWithCGImage:imageRef];
  CGImageRelease(imageRef);
  CGDataProviderRelease(provider);
  CGColorSpaceRelease(colorSpace);</p>

<p>  return self;
}</p></li>
</ul>


<p>@end</p>

<p>```</p>

<h2>总结</h2>

<p>上面2个环境搭建好后，你就可以在MacOS上试验各种图象处理算法，然后很方便地移值到iOS上。</p>

<p>一直觉得，图象和声音是移动设备上的特点和优势。因为移动设备没有了可以快速输入的键盘，屏幕也不大，在移动设备上，声音，图象和视频应该是相比文字更方便让人输入的东西。移动端APP应该利用好这些特点，才能设计出更加体贴的功能。</p>

<p>而且，通常情况下做图象处理都比较好玩，记得以前在学校做了一个在QQ游戏大厅自动下中国象棋的程序，其后台使用了网上下载的一个带命令行接口的象棋AI，然后我的代码主要做的事情就是识别象棋棋盘，然后将棋盘数据传给那个象棋AI，接着获得它返回的策略后，模拟鼠标点击来移动棋子。当时不懂什么图象算法，直接把棋子先截取下来保存，然后识别的时候做完全匹配，非常弱的办法，但是效果非常好，做出来也很好玩。嗯，所以文章最后，我想说的是：have fun!</p>
]]></content>
  </entry>
  
</feed>
